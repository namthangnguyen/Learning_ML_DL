{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition for the Happy House\n",
    "\n",
    "Trong notebook này, chúng ta sẽ làm quen với mô hình Facenet cho bài toán Face Recognition\n",
    "Các bài toán nhận dạng khuôn mặt thường chia thành hai loại:\n",
    "\n",
    "- **Face Verification** (**Xác thực**) - \"Đây có phải người X không?\". Một vài ứng dụng có thể kể đến là xác nhận dạng ảnh chân dung trên passport hoặc các kệ thống đăng nhập bằng ảnh mặt người dùng. Đây là bài toáng so sánh 1:1.\n",
    "- **Face Recognition** (**Nhận diện**) - \"Người này là ai?\". Ví dụ có thể kể đến là hệ thống checkin nhân viên tại công ty. Đây là bài toán so sánh 1:1K.\n",
    "\n",
    "Mô hình Facenet sẽ học ra một mạng neuron nhằm mã hóa một bức ảnh thành 1 vector 128 chiều (có 128 số). Bằng cách so sánh khoảng cách giữa hai vector như thế, ta có thể xác định xem hai bức ảnh có thuộc về cùng một người hay không.\n",
    "\n",
    "**Trong assignment này, bạn sẽ:**\n",
    "- Lập trình hàm triplet loss\n",
    "- Sử dụng mô hình pretrained để mã hóa khuôn mặt thành các vector 128 chiều\n",
    "- Sử dụng các vector này để thực hiện face recognition và face verification\n",
    "\n",
    "Trong bài tập, ta sẽ sử dụng mô hình một pre-trained sử dụng convention \"channels first\", trái ngược với convention \"channels last\". Cụ thể, một một batch trong training sẽ có shape là  $(m, n_C, n_H, n_W)$ (số ảnh trong batch, số kênh, chiều cao, chiều rộng), thay vì $(m, n_H, n_W, n_C)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Face Verification đơn giản\n",
    "\n",
    "Trong bài toán Face Verification, bạn được đưa hai bức ảnh và nhiệm vụ của bạn là xác định xem hai bức ảnh có thuộc về cùng một người hay không. Cách đơn giản nhất là so sánh từng cặp pixel của hai hình ảnh với nhau. Nếu sự sai khác giữa hai hình ảnh thấp hơn một ngưỡng đã được cho từ trước, đây có thể là cùng một người.\n",
    "\n",
    "<img src=\"images/pixel_comparison.png\" style=\"width:380px;height:150px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 1** </u></center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Đương nhiên, cách làm này sẽ cho kết quả rất kém, vì giá trị pixel ảnh sẽ thay đổi rất nhiều do cách yếu tố như độ sáng, góc chụp khuôn mặt, thậm chí sự thay đổi tư thể của đầu,...\n",
    "\n",
    "Ta thấy thay vì sử dụng ảnh thô, chúng ta có thể học cách mã hóa thông tin ảnh để việc đo đạc sự sai khác này được chính xác hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Mã hóa ảnh khuôn mặt thành vector 128 chiều\n",
    "\n",
    "### 1.1 - Sử dụng ConvNet  để tính toán vector mã hóa\n",
    "\n",
    "Mô hình Facenet cần một lượng lớn data và nhiều thời gian để huấn luyện. Vì vậy, ta sẽ chỉ sử dụng mô hình đã được train hẵn bởi người khác. Kiến trúc mạng sử dụng trong bài được thiết kế theo mô hình Inception trong bài báo [Szegedy *et al.*](https://arxiv.org/abs/1409.4842). Chúng ta đã có sẵn phần lập trình Inception network trong file `inception_blocks.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Những điểm quan trọng bài cần nhớ là:\n",
    "- Mạng sử dụng đầu vào là ảnh RGB có kích thước 96*96. Cụ thể, mỗi training batch sẽ có kích thước $(m, n_C, n_H, n_W) = (m, 3, 96, 96)$ (m* là số mẫu trong một batch)\n",
    "- Đầu ra của mạng là một ma trận có kích cỡ $(m, 128)$, với mỗi hàng đại diện cho một ảnh đẽ được mã hóa thành vector 128 chiều\n",
    "\n",
    "Chạy Cell phía dưới để tạo ra model cho ảnh khuôn mặt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Expected Output **\n",
    "<table>\n",
    "<center>\n",
    "Total Params: 3743280\n",
    "</center>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bằng cách sử dụng một tầng fully connected với 128 neuron làm layer cuối cùng, mô hình trả về đầu ra là một vector có size 128. Sau đó, ta dùng những vector này để tính sự sai khác giữa các khuôn mặt như sau:\n",
    "\n",
    "<img src=\"images/distance_kiank.png\" style=\"width:680px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 2**: <br> </u> <font color='purple'> Tính sự sai khác giữa hai ảnh và lấy ngưỡng là cách để xác nhận xem hai bức ảnh có thuộc về cùng một người hay không</center></caption>\n",
    "\n",
    "Vì thế, một mô hình mã hóa là tốt nếu:\n",
    "- Hai bức ảnh của cùng một người có giá trị mã hóa khá giống nhau\n",
    "- Hai bức ảnh của hai người khác nhau có giá trị mã hóa khác xa nhau\n",
    "    \n",
    "Ta ý tưởng này được thể hiện bằng hàm triplet loss, với hai giá trị mã hóa của cùng một người được \"đẩy\" lại gần nhau (Anchor và Positive), trong khi \"kéo\" giá trị mã hóa ảnh của hai người khác nhau ra xa nhau (Anchor, Negative).\n",
    " \n",
    "<img src=\"images/triplet_comparison.png\" style=\"width:280px;height:150px;\">\n",
    "<br>\n",
    "<caption><center> <u> <font color='purple'> **Figure 3**: <br> </u> <font color='purple'> Trong phần tiếp theo, ta sẽ gọi các ảnh từ trác qua phải lần lượt như sau: Anchor (A), Positive (P), Negative (N)  </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1.2 - Hàm Triplet Loss\n",
    "\n",
    "Cho một ảnh $x$, ta ký hiệu giá trị mã hóa của nó là $f(x)$, với $f$ là hàm số được tính toán bởi mạng neuron.\n",
    "\n",
    "<img src=\"images/f_x.png\" style=\"width:380px;height:150px;\">\n",
    "\n",
    "<!--\n",
    "Ta cũng sẽ cho thêm một bước chuẩn hóa tại phía cuối của mô hình để $\\mid \\mid f(x) \\mid \\mid_2 = 1$ (vector mã hóa được đưa về khoảng giá trị (0,1)).\n",
    "!-->\n",
    "\n",
    "Mỗi bản ghi dùng cho huấn luyện sẽ là bộ ba ảnh $(A, P, N)$:  \n",
    "\n",
    "- A là ảnh \"Anchor\"--một bức ảnh của một người. \n",
    "- P là ảnh \"Positive\"--một bức ảnh của cùng người đó.\n",
    "- N là ảnh \"Negative\"--một bức ảnh của một người khác.\n",
    "\n",
    "Những bộ ba này được chọn ra từ tập data huấn luyện.Ta sẽ viết $(A^{(i)}, P^{(i)}, N^{(i)})$ để ký hiệu bản ghi huấn luyện thứ $i$. \n",
    "\n",
    "Bạn sẽ muốn chắc chắn rằng một hình ảnh $A^{(i)}$ sẽ ở gần với ảnh Positive $P^{(i)}$ hơn là ảnh Negative $N^{(i)}$) bằng ít nhất một lượng $\\alpha$:\n",
    "\n",
    "$$\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 + \\alpha < \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$$\n",
    "\n",
    "Vì thế công việc của bạn là cực tiểu hóa hàm \"triplet cost\" dưới đây:\n",
    "\n",
    "$$\\mathcal{J} = \\sum^{N}_{i=1} \\large[ \\small \\underbrace{\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2}_\\text{(1)} - \\underbrace{\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2}_\\text{(2)} + \\alpha \\large ] \\small_+ \\tag{3}$$\n",
    "\n",
    "Ở đây, chúng ta sử dụng biểu tượng \"$[z]_+$\" làm ký hiệu cho $max(z,0)$.  \n",
    "\n",
    "Ghi chú:\n",
    "- Vế (1) là bình phương khoảng cách giữa Anchor \"A\" và Positive \"P\" trong bộ ba ảnh, giá trị này cần càng nhỏ càng tốt. \n",
    "- Vế (2) là bình phương khoảng cách giữa Anchor \"A\" và Negative \"N\" trong bộ ba ảnh, giá trị này cần tương đối lớn. \n",
    "- $\\alpha$ là ngưỡng. Đây là siêu tham số ta tự chọn. Ta sẽ dùng $\\alpha = 0.2$. \n",
    "\n",
    "Đa phần các ứng dụng lập trình có triplet loss sẽ có thêm một phần chuẩn hóa vector về khoảng (0,1) (i.e., $\\mid \\mid f(img)\\mid \\mid_2$=1); ở đây chúng ta chưa cần quan tâm.\n",
    "\n",
    "**Bài tập**: Lập trình hàm triplet loss được đinh nghĩa như trên. Dưới đây là 4 bước:\n",
    "1. Tính khoảng cách giữa giá trị mã hóa của Anchor và Positive: $\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2$\n",
    "2. Tính khoảng cách giữa giá trị mã hóa của Anchor và Negative: $\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$\n",
    "3. Tính công thức sau cho mỗi training example: $ \\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid - \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2 + \\alpha$\n",
    "4. Tính hàm đầy đủ bằng cách lấy max với 0 và tính tổng trên tất cả các bản ghi:\n",
    "$$\\mathcal{J} = \\sum^{N}_{i=1} \\large[ \\small \\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 - \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2+ \\alpha \\large ] \\small_+ \\tag{3}$$\n",
    "\n",
    "Những hàm hữu ích: `tf.reduce_sum()`, `tf.square()`, `tf.subtract()`, `tf.add()`, `tf.reduce_mean`, `tf.maximum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: triplet_loss\n",
    "\n",
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
    "    pos_dist = None\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
    "    neg_dist = None\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = None\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = None\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss(y_true, y_pred)\n",
    "    \n",
    "    print(\"loss = \" + str(loss.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **loss**\n",
    "        </td>\n",
    "        <td>\n",
    "           350.026\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Load mô hình huấn luyện từ trước\n",
    "\n",
    "FaceNet được huấn luyện với hàm triplet loss. Nhưng vì việc training yêu cầu rất nhiều thời gian và data, ta sẽ không huấn luyện lại từ đầu. Thay vào đó, tã sẽ sử dụng mô hình được train từ trước. Chạy cell phía dưới để thực hiện việc load mô hình, việc này có thể mất vài phút. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dưới đây là một vài ví dụ về khoảng cách giữa các ảnh:\n",
    "\n",
    "<img src=\"images/distance_matrix.png\" style=\"width:380px;height:200px;\">\n",
    "<br>\n",
    "<caption><center> <u> <font color='purple'> **Figure 4**:</u> <br>  <font color='purple'> Example of distance outputs between three individuals' encodings</center></caption>\n",
    "\n",
    "Bây giờ ta sẽ sử dụng mô hình để nhận diện khuôn mặt! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Sử dụng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đâu tiên, ta sẽ xây dựng một hệ thống **Face verification**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Face Verification\n",
    "\n",
    "Trước tiên, ta xây dựng một database cho những người cần xác thực, để tạo ra vector mã hóa ta dùng hàm`img_to_encoding(image_path, model)` để thực hiện quá trình inference với model. \n",
    "\n",
    "Chạy đoạn code dưới đây để tạo ra dictionary với mỗi key là tên người nhận diện, value là một vector mã hóa có 128 chiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
    "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
    "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
    "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
    "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
    "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
    "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
    "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
    "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Lập trình hàm verify() để kiểm tra một ảnh trong thư mục (`image_path`) có đúng là một người gọi là nào đó (gọi là \"identity\") hay không. Bạn sẽ phải đi qua những bước sau:\n",
    "1. Tính toán giá trị vector của mô hình từ thư mục image_path\n",
    "2. Tính toán khoảng cách của vector từ bước một với giá trị mã khóa của ảnh thuộc về người có cùng tên trong database\n",
    "3. Mở cửa nếu giá trị bé hơn 0.7.\n",
    "\n",
    "Chúng ta sẽ tính khoảng cách L2 bằng hàm (np.linalg.norm). (Ghi chú: Ta so sánh khoảng L2 với ngưỡng 0.7, không phải bình phương khoảng cách L2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: verify\n",
    "\n",
    "def verify(image_path, identity, database, model):\n",
    "    \"\"\"\n",
    "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
    "    \n",
    "    Arguments:\n",
    "    image_path -- path to an image\n",
    "    identity -- string, name of the person you'd like to verify the identity. Has to be a resident of the Happy house.\n",
    "    database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).\n",
    "    model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "    dist -- distance between the image_path and the image of \"identity\" in the database.\n",
    "    door_open -- True, if the door should open. False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line)\n",
    "    encoding = None\n",
    "    \n",
    "    # Step 2: Compute distance with identity's image (≈ 1 line)\n",
    "    dist = None\n",
    "    \n",
    "    # Step 3: Open the door if dist < 0.7, else don't open (≈ 3 lines)\n",
    "    if None:\n",
    "        print(\"It's \" + str(identity) + \", welcome home!\")\n",
    "        door_open = None\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = None\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Younes là người trong ảnh dưới đây, tên anh ta có trong database:\n",
    "\n",
    "<img src=\"images/camera_0.jpg\" style=\"width:100px;height:100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verify(\"images/camera_0.jpg\", \"younes\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **It's younes, welcome home!**\n",
    "        </td>\n",
    "        <td>\n",
    "           (0.65939283, True)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Benoit, người trong ảnh dưới, đã lấy trộm ID card của Kian để xác nhận, hãy chạy đoạn mã dưới để xem anh ta có được xác nhận là Kian hay không.\n",
    "<img src=\"images/camera_2.jpg\" style=\"width:100px;height:100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verify(\"images/camera_2.jpg\", \"kian\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **It's not kian, please go away**\n",
    "        </td>\n",
    "        <td>\n",
    "           (0.86224014, False)\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Face Recognition\n",
    "\n",
    "Bây giờn chúng ta sẽ xây dựng một hệ thống face recognition nhận đầu vào là ảnh của một người, đầu ra là kết quả xem người đó là ai trong database. \n",
    "\n",
    "**Bài tập**: Lập trình hàm `who_is_it()`. Bạn sẽ phải đi qua những bước sau:\n",
    "1. Tính toán giá trị mã hóa của ảnh đầu vào từ thư mục image_path\n",
    "2. Tìm giá trị mã hóa trong data base gần với lại giá trị từ bước 1 nhất. \n",
    "    - Khởi tạo giá trị `min_dist` bằng một số đủ lớn, ví dụ 100. Nó sẽ giúp bạn theo dõi được giá trị khoảng cách bé nhất.\n",
    "    - Tạo một vòng lặp với tên và giá trị mã hóa trong database. Gợi ý: sử dụng `for (name, db_enc) in database.items()`.\n",
    "        - Tính khoảng cách L2 \"encoding\" và encoding hiện tại, cho là biến dist.\n",
    "        - Nếu dist < min_dist, set min_dist thành dist, và chuyển đặt biến identity = tên người có dist = min_dist hiện tại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: who_is_it\n",
    "\n",
    "def who_is_it(image_path, database, model):\n",
    "    \"\"\"\n",
    "    Implements face recognition for the happy house by finding who is the person on the image_path image.\n",
    "    \n",
    "    Arguments:\n",
    "    image_path -- path to an image\n",
    "    database -- database containing image encodings along with the name of the person on the image\n",
    "    model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "    min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
    "    identity -- string, the name prediction for the person on image_path\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)\n",
    "    encoding = None\n",
    "    \n",
    "    ## Step 2: Find the closest encoding ##\n",
    "    \n",
    "    # Initialize \"min_dist\" to a large value, say 100 (≈1 line)\n",
    "    min_dist = None\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in None:\n",
    "        \n",
    "        # Compute L2 distance between the target \"encoding\" and the current \"emb\" from the database. (≈ 1 line)\n",
    "        dist = None\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
    "        if None:\n",
    "            min_dist = None\n",
    "            identity = None\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Người trong ảnh là Younes (\"images/camera_0.jpg\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "who_is_it(\"images/camera_0.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            **it's younes, the distance is 0.659393**\n",
    "        </td>\n",
    "        <td>\n",
    "           (0.65939283, 'younes')\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn có thể thử với các ảnh khác trong thư mục để xem kết quả.\n",
    "\n",
    "Một vài gợi ý để cải thiện hệ thống face recognition:\n",
    "- Với mỗi người ta có nhiều ảnh mã hóa (khác nhau về góc chụp, độ sáng,...) trong database, như thế sẽ làm tăng thêm độ chính xác của mô hình.\n",
    "- Cắt ảnh sao cho chỉ giữ lại phần mặt, mô hình sẽ hoạt động tốt hơn vì không phải tính toán trên các giá trị pixel thừa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "**Key takeaway**:\n",
    "  \n",
    "- Bài toán Face verification là so sánh 1:1, còn face recognition là so sánh 1:K. \n",
    "- Hàm loss sử dụng để train mô hình mã hóa ảnh khuôn mặt là triplet loss.\n",
    "- Cùng một giá trị mã hóa có thể dùng cho cả bài toán verification and recognition. Sau đó chúng ta đo khoảng cách giữa hai vector mã hóa của hai ảnh để xác nhận xem hai bức ảnh có thuộc về cùng một người không. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúc mừng bạn đã hoàn thành khóa học!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "- Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n",
    "- Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014). [DeepFace: Closing the gap to human-level performance in face verification](https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf) \n",
    "- Mô hình pretrained được lấy từ implementation của Victor Sy Wang và được load sử dụng code của tác giả: https://github.com/iwantooxxoox/Keras-OpenFace.\n",
    "- Repository chính thức của mô hình FaceNet trên github: https://github.com/davidsandberg/facenet \n",
    "- Notebook được biên soạn lại theo bản gốc của tác giả của Andrew Ng."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

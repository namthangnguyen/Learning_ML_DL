{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong notebook này, ta sẽ:\n",
    " - Làm quen với thư viện sklearn dùng cho học máy\n",
    " - Làm quen với một số kỹ thuật phổ biến cho học máy có giám sát"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Học có giám sát (supervised learning) chia làm hai loại chính: Regression (hồi quy), và Classification (phân loại)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ta load những thư viện cần sử dụng\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dưới đây là các phép đo lỗi phổ biến cho bài toán regression\n",
    "# các phép đo error này nếu giá trị càng nhỏ tức là mô hình càng fit tốt với dữ liệu\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Các phép đo phổ biến cho bài toán classification\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phần 1: Bài toán Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu giá bất động sản montreal\n",
    "# Mục tiêu: Dự đoán giá bán (ask price) của các ngôi nhà dựa trên 39 tham số\n",
    "# Ta dùng thư viện pandas để đọc bảng csv với hàm read_csv\n",
    "\n",
    "df_montreal = pd.read_csv(\"data/montreal_housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra kích thước dữ liệu bằng câu lệnh sau\n",
    "df_montreal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả cho thấy dataframe có 9717 hàng và 40 cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sựu dụng phương thức .head() để view bảng dữ liệu, hay còn gọi là dataframe\n",
    "df_montreal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách dataframe thành hai phần x và y (đầu vào và đầu ra của mô hình học máy) \n",
    "\n",
    "x = df_montreal.iloc[:, :-1]\n",
    "y = df_montreal[\"askprice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong một project học máy, dữ liệu bao giờ cũng sẽ được chia làm ít nhất hai phần:\n",
    " - Phần thứ nhất dùng để huấn luyện mô hình (training data)\n",
    " - Phần thứ hai dùng để kiểm tra hiệu năng của mô hình với các hàm đo performance (testing data)\n",
    "\n",
    "So sánh kết quả performance trên training và testing data sẽ cho ta biết:\n",
    " - Mô hình có đang fit tốt hay không\n",
    " - Có bị mắc các lỗi như overfit, underfit hay không.\n",
    "\n",
    "Từ đó, ta sẽ có phương án huấn luyện tốt hơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách dữ liệu thành training và testing set bằng hàm train_test_split của thư viện sklearn\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Để huấn luyện mô hình Linear Regression, ta dùng class Linear Regression đã import ở phía trên\n",
    "linear_reg = LinearRegression(normalize= True)\n",
    "\n",
    "# Sử dụng phương thức \".fit\" để training\n",
    "linear_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng độ đo mean_squared_error để kiểm tra hiệu năng mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing models\n",
    "y_pred_train = linear_reg.predict(x_train)\n",
    "y_pred = linear_reg.predict(x_test)\n",
    "\n",
    "print(f\"MSE on training: {mean_squared_error(y_train,y_pred_train):.3f}, on testing: {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "print(f\"MAE on training: {mean_absolute_error(y_train, y_pred_train):.3f}, on testing: {mean_absolute_error(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng Linear Regression không tốt cho trường hợp này lắm => Thử những mô hình cao cấp hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sẽ sử dụng hai mô hình nâng cao của Linear Regression là Ridge và Lasso, hai mô hình này có thêm tham số chuẩn hóa giúp mô hình bớt bị overfit hơn\n",
    "\n",
    "Ban chưa cần quan tâm đến lý thuyết của hai mô hình này vội, vì chúng sẽ được dạy ở buổi 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "ridge = Ridge(alpha = 0.1, normalize= True)\n",
    "ridge.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing models\n",
    "y_pred_train = ridge.predict(x_train)\n",
    "y_pred = ridge.predict(x_test)\n",
    "\n",
    "print(f\"MSE on training: {mean_squared_error(y_train, y_pred_train):.3f}, on testing: {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "print(f\"MAE on training: {mean_absolute_error(y_train, y_pred_train):.3f}, on testing: {mean_absolute_error(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy model đã giảm lỗi MSE, tuy nhiên vẫn khá cao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha = 0.001, normalize= True)\n",
    "lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing models\n",
    "y_pred_train = lasso.predict(x_train)\n",
    "y_pred = lasso.predict(x_test)\n",
    "\n",
    "print(f\"MSE on training: {mean_squared_error(y_train, y_pred_train):.3f}, on testing: {mean_squared_error(y_test, y_pred):.3f}\")\n",
    "print(f\"MAE on training: {mean_absolute_error(y_train, y_pred_train):.3f}, on testing: {mean_absolute_error(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thấy với hồi quy Lasso và Ridge, model đã bớt bị overfit hơn rất nhiều. Tuy nhiên, độ chính xác của hai mô hình này phụ thuộc vào giá trị của tham số alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phần 2: Bài toán Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = pd.read_csv(\"data/iris.csv\", index_col = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mục tiêu: Dự đoán loài hoa dựa vào 4 thông số từ sepal length đến petal width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nhận xét: dữ liệu có kích thước khá nhỏ nên tiến hành evaluation bằng cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('cross-validation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giải thích cross_validation:\n",
    "    Ta chia dữ liệu ra làm n phần và tiến hành training n lần\n",
    "    - Với mỗi một lần training ta lấy một phần trong n dataset nhỏ làm testing data, và (n-1) còn lại làm training data\n",
    "    - Lần lượt huấn luyện cho đến khi cả n dataset nhỏ đều được dùng để làm test\n",
    "    - Kết quả đo performance cuối cùng sẽ là trung bình của n lần đo performance trên các dataset nhỏ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_iris.iloc[:, :-1]\n",
    "y = df_iris[\"Species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = LabelEncoder()\n",
    "y_new = label_encode.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode.inverse_transform([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# scoring = {'precision': make_scorer(accuracy_score),\n",
    "#             'f1': make_scorer(f1_score)}\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Khi ta chạy hàm cross_calidate, kết quả trả về sẽ là một dictionary lưu trữ thông tin của quá trình huấn luyện\n",
    "scores = cross_validate(clf, x, y_new, scoring=scoring, cv=5, return_train_score=True, return_estimator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong đó:\n",
    "- estimator là tham số của các mô hình đã được huấn luyện\n",
    "- fit_time, score_time là thời gian huấn luyện và đánh giá cho mỗi lần validation\n",
    "- test/train_<tên độ đo> là kết quả đo của độ đo performance trên tập train và test cho mỗi lần validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores['train_precision_macro'])\n",
    "print(scores['test_precision_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mỗi giá trị test/train_precision_macro là một mảng numpy, ta có thể dùng phương thức ndarray.mean() để tìm độ\n",
    "# chính xác trung bình\n",
    "print(scores['train_precision_macro'].mean())\n",
    "print(scores['test_precision_macro'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra độ đo recall trên train và test\n",
    "\n",
    "print(scores['train_recall_macro'])\n",
    "print(scores['test_recall_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores['train_recall_macro'].mean())\n",
    "print(scores['test_recall_macro'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gõ key estimator để  truy xuất ra các mô hình trong quá trình cross val\n",
    "# Mỗi mô hình sau khi được huấn luyện xong sẽ được ký hiệu là một object như sau\n",
    "scores[\"estimator\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gõ coeff_ để truy xuất ra trọng số của mỗi LogisticRegression object như sau\n",
    "scores[\"estimator\"][0].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key takeaway:**\n",
    "\n",
    "- Training và testing là hai phần không thể tách rời trong một project machine learning\n",
    "- Ta có thể sử dụng thư viện sklearn để áp dụng các mô hình học máy và các kỹ thuật xử lý số liệu cho machine learning\n",
    "- Các model học máy được lưu trữ dưới dạng các class trong thư viện sklearn\n",
    "- Để tiến hành huấn luyện mô hình, ta khởi tạo một biến với class là tên mô hình đó (ví dụ LinearRegression, Logistic Regression) và sử dụng phương thức \".fit\"\n",
    "- Mỗi một loại bài toán sẽ có những độ đo phù hợp, ta có thể tìm implementation của các độ đo đó tại sub-package sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để hiểu thêm về cách sử dụng thư viện sklearn, ta có thể xem trang web của sklearn [tại đậy](https://scikit-learn.org/stable/index.html) \n",
    "\n",
    "Sách tham khảo về học máy với sklearn: [scikit-learn Cookbook](https://github.com/whoafridi/Machine-Learning-Books/blob/master/book/scikit-learn%20Cookbook%20-%20Second%20Edition.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
